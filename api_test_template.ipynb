{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Quality Companion API Test Template\n",
    "\n",
    "This notebook demonstrates how to use the AI Quality Companion API with different LLM providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from IPython.display import display, JSON\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# API Configuration\n",
    "API_URL = \"http://localhost:8000\"\n",
    "\n",
    "# API Keys (you can set these as environment variables instead)\n",
    "API_KEYS = {\n",
    "    \"groq\": os.getenv(\"GROQ_API_KEY\"),\n",
    "    \"openai\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"anthropic\": os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "}\n",
    "\n",
    "# Available Models\n",
    "MODELS = {\n",
    "    \"groq\": [\"llama3-8b-8192\"],\n",
    "    \"openai\": [\"gpt-4\", \"gpt-3.5-turbo\"],\n",
    "    \"anthropic\": [\"claude-3-opus\", \"claude-3-sonnet\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def make_request(prompt, provider=\"groq\", model=None, api_key=None):\n",
    "    \"\"\"\n",
    "    Make a request to the API with the specified configuration.\n",
    "    \n",
    "    Parameters:\n",
    "    - prompt (str): The analysis request\n",
    "    - provider (str): LLM provider (groq, openai, anthropic)\n",
    "    - model (str): Specific model to use (if None, uses default for provider)\n",
    "    - api_key (str): API key (if None, uses environment variable)\n",
    "    \"\"\"\n",
    "    # Prepare request data\n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"thread_id\": f\"test_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    }\n",
    "    \n",
    "    # Add LLM configuration if specified\n",
    "    if provider != \"groq\" or model is not None:\n",
    "        data[\"llm_config\"] = {\n",
    "            \"model\": f\"{provider}:{model or MODELS[provider][0]}\",\n",
    "            \"api_key\": api_key or API_KEYS[provider]\n",
    "        }\n",
    "    \n",
    "    # Make the request\n",
    "    response = requests.post(f\"{API_URL}/analyze\", json=data)\n",
    "    \n",
    "    # Return formatted response\n",
    "    return {\n",
    "        \"status_code\": response.status_code,\n",
    "        \"response\": response.json() if response.status_code == 200 else response.text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. FMEA Analysis with Default Groq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "fmea_prompt = \"\"\"\n",
    "Conduct an FMEA for our new product assembly line:\n",
    "- Process step: Final assembly of electronic components\n",
    "- Potential failure modes\n",
    "- Effects of each failure\n",
    "- Causes of failures\n",
    "- Current controls\n",
    "Rate severity, occurrence, and detection (1-10 scale)\n",
    "Provide RPN calculations and recommendations.\n",
    "\"\"\"\n",
    "\n",
    "result = make_request(fmea_prompt)\n",
    "display(JSON(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SIPOC Diagram with OpenAI GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "sipoc_prompt = \"\"\"\n",
    "Create a SIPOC diagram for:\n",
    "Process: Product Assembly\n",
    "Suppliers: Raw Material Vendor, Component Supplier\n",
    "Inputs: Raw Materials, Components, Assembly Instructions\n",
    "Process Steps: Material Inspection, Assembly, Quality Check, Packaging\n",
    "Outputs: Finished Products, Quality Reports\n",
    "Customers: Distributors, End Users\n",
    "\"\"\"\n",
    "\n",
    "result = make_request(sipoc_prompt, provider=\"openai\", model=\"gpt-4\")\n",
    "display(JSON(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fishbone Diagram with Anthropic Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "fishbone_prompt = \"\"\"\n",
    "Create a fishbone diagram for quality issue:\n",
    "Problem: Inconsistent product quality\n",
    "Categories to analyze:\n",
    "- Machine factors\n",
    "- Method factors\n",
    "- Material factors\n",
    "- Measurement factors\n",
    "- Environment factors\n",
    "- People factors\n",
    "Show cause-effect relationships visually.\n",
    "\"\"\"\n",
    "\n",
    "result = make_request(fishbone_prompt, provider=\"anthropic\", model=\"claude-3-sonnet\")\n",
    "display(JSON(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create your own test here\n",
    "custom_prompt = \"\"\"\n",
    "Your custom prompt here\n",
    "\"\"\"\n",
    "\n",
    "# Choose provider and model\n",
    "provider = \"groq\"  # or \"openai\" or \"anthropic\"\n",
    "model = None  # or specific model name\n",
    "\n",
    "result = make_request(custom_prompt, provider=provider, model=model)\n",
    "display(JSON(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
} 