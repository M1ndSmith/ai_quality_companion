{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Quality Companion API Test Template\n",
    "\n",
    "This notebook demonstrates how to use the AI Quality Companion API with different LLM providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from IPython.display import display, JSON\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "API_URL = \"http://localhost:8000\"\n",
    "\n",
    "# API Keys (you can set these as environment variables instead)\n",
    "API_KEYS = {\n",
    "    \"groq\": os.getenv(\"GROQ_API_KEY\"),\n",
    "    \"openai\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"anthropic\": os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "}\n",
    "\n",
    "# Available Models\n",
    "MODELS = {\n",
    "    \"groq\": [\"llama3-8b-8192\"],\n",
    "    \"openai\": [\"gpt-4\", \"gpt-3.5-turbo\"],\n",
    "    \"anthropic\": [\"claude-3-opus\", \"claude-3-sonnet\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(prompt, provider=\"groq\", model=None, api_key=None):\n",
    "    \"\"\"\n",
    "    Make a request to the API with the specified configuration.\n",
    "    \n",
    "    Parameters:\n",
    "    - prompt (str): The analysis request\n",
    "    - provider (str): LLM provider (groq, openai, anthropic)\n",
    "    - model (str): Specific model to use (if None, uses default for provider)\n",
    "    - api_key (str): API key (if None, uses environment variable)\n",
    "    \"\"\"\n",
    "    # Prepare request data\n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"thread_id\": f\"test_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    }\n",
    "    \n",
    "    # Add LLM configuration if specified\n",
    "    if provider != \"groq\" or model is not None:\n",
    "        data[\"llm_config\"] = {\n",
    "            \"model\": f\"{provider}:{model or MODELS[provider][0]}\",\n",
    "            \"api_key\": api_key or API_KEYS[provider]\n",
    "        }\n",
    "    \n",
    "    # Make the request\n",
    "    response = requests.post(f\"{API_URL}/analyze\", json=data)\n",
    "    \n",
    "    # Return formatted response\n",
    "    return {\n",
    "        \"status_code\": response.status_code,\n",
    "        \"response\": response.json() if response.status_code == 200 else response.text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. FMEA Analysis with Default Groq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "response": {
        "response": null,
        "status": "success"
       },
       "status_code": 200
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fmea_prompt = \"\"\"\n",
    "Conduct an FMEA for our new product assembly line:\n",
    "- Process step: Final assembly of electronic components\n",
    "- Potential failure modes\n",
    "- Effects of each failure\n",
    "- Causes of failures\n",
    "- Current controls\n",
    "Rate severity, occurrence, and detection (1-10 scale)\n",
    "Provide RPN calculations and recommendations.\n",
    "\"\"\"\n",
    "\n",
    "result = make_request(fmea_prompt)\n",
    "display(JSON(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SIPOC Diagram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "response": {
        "response": null,
        "status": "success"
       },
       "status_code": 200
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sipoc_prompt = \"\"\"\n",
    "Create a SIPOC diagram for:\n",
    "Process: Product Assembly\n",
    "Suppliers: Raw Material Vendor, Component Supplier\n",
    "Inputs: Raw Materials, Components, Assembly Instructions\n",
    "Process Steps: Material Inspection, Assembly, Quality Check, Packaging\n",
    "Outputs: Finished Products, Quality Reports\n",
    "Customers: Distributors, End Users\n",
    "\"\"\"\n",
    "\n",
    "result = make_request(sipoc_prompt)\n",
    "display(JSON(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fishbone Diagram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "response": {
        "response": null,
        "status": "success"
       },
       "status_code": 200
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fishbone_prompt = \"\"\"\n",
    "Create a fishbone diagram for quality issue:\n",
    "Problem: Inconsistent product quality\n",
    "Categories to analyze:\n",
    "- Machine factors\n",
    "- Method factors\n",
    "- Material factors\n",
    "- Measurement factors\n",
    "- Environment factors\n",
    "- People factors\n",
    "Show cause-effect relationships visually.\n",
    "\"\"\"\n",
    "\n",
    "result = make_request(fishbone_prompt)\n",
    "display(JSON(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "response": {
        "response": null,
        "status": "success"
       },
       "status_code": 200
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eight_d_prompts = \"\"\"\n",
    "Generate an 8D report for customer complaint:\n",
    "1. Team formation\n",
    "2. Problem description\n",
    "3. Containment actions\n",
    "4. Root cause analysis\n",
    "5. Corrective actions\n",
    "6. Implement solutions\n",
    "7. Preventive measures\n",
    "8. Team recognition\n",
    "Include timeline, actions, and effectiveness measures.\n",
    "\"\"\"\n",
    "\n",
    "result = make_request(eight_d_prompts)\n",
    "display(JSON(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your own test here\n",
    "custom_prompt = \"\"\"\n",
    "Your custom prompt here\n",
    "\"\"\"\n",
    "\n",
    "# Choose provider and model\n",
    "provider = \"groq\"  # or \"openai\" or \"anthropic\"\n",
    "model = None  # or specific model name\n",
    "\n",
    "result = make_request(custom_prompt, provider=provider, model=model)\n",
    "display(JSON(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
